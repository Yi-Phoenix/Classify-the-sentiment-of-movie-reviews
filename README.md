# Classify-the-sentiment-of-movie-reviews
## Introduction
  Sentiment is a thought, opinion, or idea based on a feeling about a situation, or a way of thinking about something. Sentiment classification is a challenging classification task, which uses natural language processing, text analysis, computational linguistics, and biometrics to identify opinions and emotions in text and assign proper sentimental labels (such as positive, negative, or neutral) to them. Sentiment classification has been widely used in business and product development settings to understand how customers feel about products, services, or brand. The objective of this project is to conduct sentiment classification on the Rotten Tomatoes dataset using a variety of classifiers and evaluate/compare the prediction results. 
## Dataset
  The Rotten Tomatoes movie review dataset (accessible at: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews) contains a corpus of movie reviews used for sentiment analysis, which is originally collected by Pang and Lee (2006). Later, Socher et al. (2013) created fine-grained labels for all parsed phrases in the corpus using Amazon's Mechanical Turk. As a result, the text in Rotten Tomatoes dataset is not complete sentences but parsed short phrases. The dataset includes a total of 156,060 training data and 66,292 testing data. The training set has 4 columns: PhraseId, SentenceId, Phrase, and Sentiment, while the test set has the first three but no Sentiment. The first ten training samples are shown in Table 1. The length of each phrase varies, and some phrase may just contain one stop word (e.g., phrase 4 and 7) or one punctuation. However, the same stop word may have very different labels, leading to a certain challenge in this data set.
  The training data are classified into 5 classes, which are 0-negative, 1-somewhat negative, 2-neutral, 3-somewhat positive, 4-positive. There is a natural order among the different classes. Such ordering information can be used during the classification task. Notably, neutral is the dominant class whose number of data points is over 10 times than the number of data points from the most minor class (negative; Figure 1). 
  ![class distribution](distribution_original_classes_train.png)
  
## Methods
### Sentence and text embedding
  Recent studies have demonstrated strong transfer task performance using pre-trained sentence level embeddings (Conneau et al., 2017, Cer et al., 2018). The models take strings as input and produce an embedding representation of the string with a fixed dimension as output. The sentence level embeddings differ significantly from traditional bag of words approach in converting text information into numerical vectors to create features for machine learning classifiers. The bag of words approach simply counts how many times a word appears in a document and does not consider the relationship between different words within a sentence. However, sentence level embeddings such as Sentence Transformers make use of sophisticated Recurrent Neural Network (RNN) framework to learn text information at sentence level, which enables this approach to consider the text dependencies and connections. As a result, sentence level embeddings are normally preferred for complicated text classification such as sentiment classification. 
  The pre-trained embedding language models are publicly available in SentenceTransformers which is a Python framework for state-of-the-art sentence and text embeddings (www.SBERT.net). There are 26 models that were trained on SNLI and MultiNLI and then fine-tuned on the Semantic Textual Similarity (STS) benchmark train set. The ‘roberta-large-nli-stsb-mean-tokens’ model was used for this project as it has the highest STSb performance (86.39). We used GPU under Google Collaboratory to run the SentenceTransformers. The resulting training and test sets have dimension 156,060 × 1024 and 66292 × 1024, respectively.  
### Training set splitting
  Because the test data set has no sentiment labels and in order to better guide the downstream classification task, we decided to only use the training set to perform the classification. Additionally, the training dataset with a total of 156,060 phrases is too big to train classifiers within a reasonable time frame especially when the classifiers need parameter-tuning. As a result, we decided to subsample training data from each sentiment class to further reduce the size of the training set and simultaneously address the issue of unbalanced classes. As shown in Figure 1, the training set is class-imbalanced with negative class to positive class ratio as 1: 3.9 : 11.3 : 4.7 : 1.3. For each of the class, we randomly split train and test with a prefixed ratio to manually balance the five classes for training. Specifically, the proportions of training size in the five classes from negative, somewhat negative, neutral, somewhat positive, to positive are 2/3, 1/3, 1/5, 1/4, and 2/3 respectively. Thus, the resulting training set has 4714, 9091, 15916, 8231, and 6137 phrase counts for their corresponding class respectively (Figure 2). The largest class ratio is 3.4 (neutral versus negative) which is lower than 5, thus we regard the new training set as relatively “balanced”. For the test data set, we then have 2358, 18182, 63666, 24696, and 3069 phase counts for their corresponding class respectively. We then used the new training (44089 × 1024) and test sets (111971 × 1024) for the following classification task. 
  ![class distribution resampled](distribution_resampled_classes_train.png)

